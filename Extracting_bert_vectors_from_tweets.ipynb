{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "up1OYuJfvVdi",
        "K4noMgFP3ADX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshay-Kumar-Arya/Identify_the_sentiments/blob/master/Extracting_bert_vectors_from_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-g_CPLtHrFq",
        "colab_type": "text"
      },
      "source": [
        "# Identify the Sentiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG9n3fVzsGrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install modules\n",
        "!pip install -q tensorflow\n",
        "!pip install -q tensorflow_hub\n",
        "!pip install -q bert-for-tf2\n",
        "#!pip install -q sentencepiece\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScDKcwmuRJ8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "21f9d2c7-b251-4b9f-80fd-d791ad75507c"
      },
      "source": [
        "# import Modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "import re\n",
        "import pickle\n",
        "#import math\n",
        "\n",
        "# To visualize tweets upto larger width\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "print(\"TF version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version:  2.2.0\n",
            "Hub version:  0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m17YKicdRCoa",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRfhnlCsQcbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "92a69a6f-acdd-48d8-de48-c42b723e47c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHVNZms4HwAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data path\n",
        "training_data_path = \"/content/gdrive/My Drive/Identify_the_sentiments/train.csv\"\n",
        "test_data_path =  \"/content/gdrive/My Drive/Identify_the_sentiments/test.csv\"\n",
        "\n",
        "save_path = \"/content/gdrive/My Drive/Identify_the_sentiments/\""
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj4_Wb4nQ0B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading data from csv\n",
        "train_data = pd.read_csv(training_data_path)\n",
        "test_data = pd.read_csv(test_data_path)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlPJGbKvQ-jW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a3ad9d74-aea9-43ad-ae12-3bcef1cae949"
      },
      "source": [
        "# data visualization\n",
        "print(f\"Number of training examples: {train_data.shape[0]}\", '\\n')\n",
        "print(f\"Number of test examples: {test_data.shape[0]}\", '\\n')\n",
        "\n",
        "print(f\"The fraction of positive and negative comments:\")\n",
        "print(train_data['label'].value_counts(normalize = True), '\\n')\n",
        "\n",
        "print(\"Training Dataframe:\")\n",
        "print(train_data.head())"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 7920 \n",
            "\n",
            "Number of test examples: 1953 \n",
            "\n",
            "The fraction of positive and negative comments:\n",
            "0    0.744192\n",
            "1    0.255808\n",
            "Name: label, dtype: float64 \n",
            "\n",
            "Training Dataframe:\n",
            "   id  ...                                                                                                                                tweet\n",
            "0   1  ...     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone\n",
            "1   2  ...  Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/\n",
            "2   3  ...          We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu\n",
            "3   4  ...                     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/\n",
            "4   5  ...         What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXYPslMkRZt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing URLs from data\n",
        "train_data['clean_tweet'] = train_data['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "test_data['clean_tweet'] = test_data['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVg_KYKz5BFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove twitter handles\n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt4Rc4j_Sa_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove punctuations\n",
        "punctuation = '.,\\'!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
        "              \n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].apply(lambda x: \"\".join(ch for ch in x if ch not in set(punctuation)))\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].apply(lambda x: \"\".join(ch for ch in x if ch not in set(punctuation)))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4UL7TouVqQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to lower case\n",
        "\n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].str.lower()\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].str.lower()"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0hK9C9WYA8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove the numbers\n",
        "\n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].str.replace(\"[0-9]\", \" \")"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6RVYH9MGHJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove white spaces\n",
        "\n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].apply(lambda x: ' '.join(x.split()))\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].apply(lambda x: ' '.join(x.split()))"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up1OYuJfvVdi",
        "colab_type": "text"
      },
      "source": [
        "#### Bert feature embedding extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1HM711NvmEy",
        "colab_type": "text"
      },
      "source": [
        "To get feature extraction follow the following steps\n",
        " * Install `bert-for-tf2`module and import `bert`.\n",
        " * First get the tokenizer using `get_tokenizer` function\n",
        " * Add `\"[CLS]\"` and `\"[SEP]\"` token respectively at the start and end of the tokenized sequence\n",
        " * Get inpus_ids, input_mask and input_segments using `get_ids`, `get_masks` and `get_segments` function respectively.\n",
        " * Get model using `embedding_model` function.\n",
        " * Convert input into Numpy arrays. The shape of input should be `[batch_size, maximum_sequence_length]`.\n",
        " * Use model.predict to get the output. Use `model.predict([[input_ids],[input_masks],[input_segments]])` or `model.predict([input_ids,input_masks,input_segments])`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o2PYFYY0x12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import bert_layer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=True)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEL8YW6ayljD",
        "colab_type": "text"
      },
      "source": [
        "**Bert tokenizer:** \n",
        "* The methodology on which BERT was trained using the WordPiece tokenization. It means that a word can be broken down into more than one sub-words.\n",
        "* Import tokenizer using the original vocab file, do lower case all the word pieces and then tokenize the sentences.\n",
        "\n",
        "For example:\n",
        "* **Input:** `'Hi we are using BERT'`\n",
        "* **Output:** `['hi', 'we', 'are', 'using', 'bert']`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mECsA2kx0mH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build tokenizer function\n",
        "\n",
        "def get_tokenizer():\n",
        "  FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "  vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "  do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "  tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
        "  return tokenizer"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JFqzhQwtVuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building architecture of model\n",
        "\n",
        "def embedding_model(max_seq_length = 128):\n",
        "  # the input of model should be numpy arrays\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
        "  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])\n",
        "  return model"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYBac5ynzh9L",
        "colab_type": "text"
      },
      "source": [
        "**Code Explanation:**\n",
        "\n",
        "* **max_seq_length = 128**\n",
        "  * BERT has a constraint on the maximum length of a sequence after tokenizing. For any BERT model, the maximum sequence length after tokenization is 512. But we can set any sequence length equal to or below this value.\n",
        "\n",
        "* **Inputs:**\n",
        "  * input token ids (tokenizer converts tokens using vocab file)\n",
        "  * input masks (1 for useful tokens, 0 for padding)\n",
        "  * segment ids (for 2 text training: 0 for the first one, 1 for the second one)\n",
        "* **Outputs:**\n",
        "   * pooled_output of shape [batch_size, 768] with representations for the entire input sequences \n",
        "   * sequence_output of shape [batch_size, max_seq_length, 768] with representations for each input token (in context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ySkNhqt2FNm",
        "colab_type": "text"
      },
      "source": [
        "**BERT original implementation of generating segments and masks:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dhQrKT4mcLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See BERT paper: https://arxiv.org/pdf/1810.04805.pdf\n",
        "# And BERT implementation convert_single_example() at https://github.com/google-research/bert/blob/master/run_classifier.py\n",
        "\n",
        "def get_masks(tokens, max_seq_length=128):\n",
        "    \"\"\"Mask for padding\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_segments(tokens, max_seq_length=128):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length=128):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4noMgFP3ADX",
        "colab_type": "text"
      },
      "source": [
        "#### One small example for extraction of embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo-XFvJjmxoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding separator tokens according to the paper\n",
        "\n",
        "#[CLS] provided by BERT for sentence embeddings without any combination or processing from all the word vectors in the sentence.\n",
        "s = \"Hi we are using BERT\"\n",
        "\n",
        "stokens = tokenizer.tokenize(s)\n",
        "\n",
        "stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        "\n",
        "input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
        "input_masks = get_masks(stokens, max_seq_length)\n",
        "input_segments = get_segments(stokens, max_seq_length)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRkfMiLQpgIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting list into arrays\n",
        "input_ids = np.array(input_ids)\n",
        "input_masks = np.array(input_masks)\n",
        "input_segments = np.array(input_segments)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8uY_FW7qyMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "640e0e26-53bd-4881-a3bb-daf052dc423c"
      },
      "source": [
        "input_ids.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq5yeUq8qfka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding batch dimension\n",
        "input_ids = input_ids[np.newaxis,]\n",
        "input_masks = input_masks[np.newaxis,]\n",
        "input_segments = input_segments[np.newaxis,]"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNxHo-7q6Hri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9715aa17-4e51-4268-a0de-7c6a289ea8c4"
      },
      "source": [
        "input_ids.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vVSlK4onUlD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1cd8c088-5b91-4558-ba74-e5f5662ede4a"
      },
      "source": [
        "print(stokens)\n",
        "print(input_ids)\n",
        "print(input_masks)\n",
        "print(input_segments)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'hi', 'we', 'are', 'using', 'bert', '[SEP]']\n",
            "[[  101  7632  2057  2024  2478 14324   102     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n",
            "[[1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOL6VB79nZnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract feature embedding\n",
        "pool_embs, all_embs = model.predict([input_ids,input_masks,input_segments])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV-I98F_nnu3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a221ef99-5921-4f68-bcd5-d0ed486d6623"
      },
      "source": [
        "pool_embs"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-8.37910175e-01, -2.29771748e-01,  9.79753584e-02,\n",
              "         6.81168735e-01, -1.24071524e-01, -9.38553140e-02,\n",
              "         8.68438244e-01,  1.70397267e-01,  2.66095459e-01,\n",
              "        -9.99814689e-01,  1.50845036e-01,  3.17748368e-01,\n",
              "         9.70117331e-01, -1.59248844e-01,  9.11800981e-01,\n",
              "        -4.88027602e-01,  1.43237943e-02, -5.00323713e-01,\n",
              "         3.12510669e-01, -6.54799461e-01,  5.54589808e-01,\n",
              "         9.74681973e-01,  6.18222952e-01,  1.98275760e-01,\n",
              "         2.67373919e-01,  4.54036117e-01, -5.74853301e-01,\n",
              "         9.19355690e-01,  9.29784775e-01,  5.73712468e-01,\n",
              "        -6.49026275e-01,  7.66068771e-02, -9.75605726e-01,\n",
              "        -1.56982809e-01, -7.71182403e-02, -9.74963188e-01,\n",
              "         1.49606138e-01, -7.06762195e-01,  2.16055159e-02,\n",
              "         9.01458412e-02, -8.69107187e-01,  1.76298708e-01,\n",
              "         9.97606575e-01, -3.85354370e-01, -2.00644415e-02,\n",
              "        -2.90139973e-01, -9.99891102e-01,  1.18405864e-01,\n",
              "        -8.36001635e-01, -2.53294766e-01, -8.05879757e-02,\n",
              "        -5.31581283e-01,  7.91633204e-02,  2.91988313e-01,\n",
              "         3.25047106e-01,  3.80862266e-01, -2.10804030e-01,\n",
              "         9.27320272e-02, -1.23464540e-01, -4.51852173e-01,\n",
              "        -5.12415171e-01,  2.68480748e-01, -1.54301092e-01,\n",
              "        -8.73806119e-01, -2.73864418e-01, -2.87236422e-01,\n",
              "        -6.02994114e-05, -1.21032588e-01, -1.71616897e-02,\n",
              "        -1.69101983e-01,  8.30683589e-01,  1.80015460e-01,\n",
              "         4.20829684e-01, -7.86027908e-01, -3.03620309e-01,\n",
              "         8.98575261e-02, -4.25269812e-01,  9.99999464e-01,\n",
              "        -3.55638891e-01, -9.60001111e-01, -8.39244798e-02,\n",
              "        -1.08037584e-01,  2.67498434e-01,  5.14027834e-01,\n",
              "        -3.10162455e-01, -9.99993861e-01,  2.20552653e-01,\n",
              "        -1.82693079e-03, -9.84159768e-01,  1.26776055e-01,\n",
              "         3.57159495e-01, -8.74651968e-02, -3.26468349e-01,\n",
              "         3.53924602e-01, -3.09264004e-01, -1.36206731e-01,\n",
              "        -2.14565769e-01,  2.44829897e-02, -1.66123629e-01,\n",
              "         1.59003446e-03, -1.33427614e-02, -1.56112373e-01,\n",
              "        -2.75733136e-02, -3.06794792e-01,  8.76392145e-03,\n",
              "        -2.19593287e-01, -3.72413844e-01,  1.28206074e-01,\n",
              "        -2.00065807e-01,  5.72368503e-01,  2.65770376e-01,\n",
              "        -2.17985153e-01,  2.12244913e-01, -9.37533915e-01,\n",
              "         4.99067724e-01, -1.73580721e-01, -9.69732404e-01,\n",
              "        -3.29842567e-01, -9.78573680e-01,  6.26428545e-01,\n",
              "        -9.95342270e-04, -4.28890325e-02,  9.41412568e-01,\n",
              "         5.04331350e-01,  2.41177946e-01,  5.67374518e-03,\n",
              "         2.45428368e-01, -9.99999881e-01, -2.53968716e-01,\n",
              "        -3.35045248e-01,  1.64709300e-01,  5.88205643e-03,\n",
              "        -9.64891315e-01, -9.34912860e-01,  5.02529263e-01,\n",
              "         9.39950943e-01,  8.51961374e-02,  9.96058583e-01,\n",
              "        -1.70382157e-01,  9.03513551e-01,  1.81431308e-01,\n",
              "        -1.07683182e-01, -3.91762972e-01, -3.26792479e-01,\n",
              "         4.57781971e-01,  3.64480138e-01, -6.16884172e-01,\n",
              "         1.42001048e-01,  6.95195720e-02, -1.31871790e-01,\n",
              "        -9.03964043e-02, -1.69332609e-01,  1.26638114e-01,\n",
              "        -9.26201820e-01, -3.66353869e-01,  9.18877482e-01,\n",
              "         1.58093780e-01,  1.60611376e-01,  6.14976406e-01,\n",
              "        -1.14804313e-01, -3.59451562e-01,  8.14848006e-01,\n",
              "         3.01605910e-01,  2.33053073e-01,  1.90780219e-02,\n",
              "         2.44346261e-01, -3.36404219e-02,  4.43640620e-01,\n",
              "        -7.65151560e-01,  2.34066740e-01,  2.72022724e-01,\n",
              "        -1.47962213e-01,  1.21517844e-01, -9.54874754e-01,\n",
              "        -2.46260062e-01,  4.43757921e-01,  9.79482472e-01,\n",
              "         7.20354319e-01,  1.76943183e-01, -2.05662660e-02,\n",
              "        -1.67704418e-01,  2.26184681e-01, -9.26528215e-01,\n",
              "         9.65050340e-01, -1.33465290e-01,  1.75876960e-01,\n",
              "         3.57879788e-01, -1.24022163e-01, -8.10842216e-01,\n",
              "        -3.45262051e-01,  7.88800657e-01, -2.82333679e-02,\n",
              "        -7.96805978e-01,  1.12304606e-01, -4.09504503e-01,\n",
              "        -3.27105582e-01,  6.00457452e-02,  4.55421865e-01,\n",
              "        -1.97725013e-01, -3.29802126e-01,  5.79552203e-02,\n",
              "         9.08979237e-01,  9.55116272e-01,  7.48527408e-01,\n",
              "        -5.66993177e-01,  5.19903898e-01, -8.73922706e-01,\n",
              "        -3.48125935e-01,  5.60471416e-02,  2.31050313e-01,\n",
              "         7.30007738e-02,  9.86302793e-01, -2.71417171e-01,\n",
              "        -1.02982940e-02, -9.04737830e-01, -9.73250628e-01,\n",
              "        -6.59923330e-02, -8.19799542e-01,  5.14730029e-02,\n",
              "        -6.33381963e-01,  2.55164891e-01,  4.99876082e-01,\n",
              "        -3.84799242e-02,  3.06384832e-01, -9.73483741e-01,\n",
              "        -7.59298861e-01,  2.48770416e-01, -1.85000807e-01,\n",
              "         3.33589762e-01, -1.58966884e-01,  3.47560495e-01,\n",
              "        -4.33411673e-02, -4.39856857e-01,  7.24270880e-01,\n",
              "         8.63639534e-01,  2.86574483e-01, -6.88171506e-01,\n",
              "         8.10554981e-01, -2.21554220e-01,  8.33500624e-01,\n",
              "        -4.85317111e-01,  9.61445510e-01,  1.63098693e-01,\n",
              "         4.40032631e-01, -8.98406982e-01,  1.28851578e-01,\n",
              "        -8.41092408e-01,  4.47217859e-02, -2.70608184e-03,\n",
              "        -4.98769224e-01, -7.05878362e-02,  3.51652116e-01,\n",
              "         1.97525680e-01,  6.82192683e-01, -3.64201784e-01,\n",
              "         9.92655456e-01, -3.69066626e-01, -9.30217981e-01,\n",
              "         2.33687580e-01, -1.65094901e-02, -9.75837171e-01,\n",
              "         4.41531725e-02,  1.83505028e-01, -4.62239027e-01,\n",
              "        -3.07274669e-01, -4.21725243e-01, -9.24067616e-01,\n",
              "         8.31376374e-01,  7.88574666e-02,  9.78080571e-01,\n",
              "         4.64647710e-02, -8.85831833e-01, -1.63306043e-01,\n",
              "        -8.67502332e-01, -2.19359249e-01, -5.84150515e-02,\n",
              "         5.73089838e-01, -2.02567950e-01, -9.38926160e-01,\n",
              "         3.58271062e-01,  4.84586358e-01,  3.33731234e-01,\n",
              "         3.20298284e-01,  9.91837919e-01,  9.99500751e-01,\n",
              "         9.54594731e-01,  8.66707444e-01,  8.81316066e-01,\n",
              "        -9.20600832e-01, -2.86312541e-03,  9.99920309e-01,\n",
              "        -5.47777176e-01, -9.99982476e-01, -9.13673699e-01,\n",
              "        -4.50540692e-01,  3.29080492e-01, -9.99999821e-01,\n",
              "         1.76827312e-02,  4.93130125e-02, -8.76960397e-01,\n",
              "        -2.60279506e-01,  9.61516023e-01,  9.78114247e-01,\n",
              "        -9.99999166e-01,  7.97101140e-01,  9.02910352e-01,\n",
              "        -4.36440200e-01,  2.83444315e-01, -6.45528585e-02,\n",
              "         9.56287861e-01,  3.63379836e-01,  2.62580901e-01,\n",
              "        -1.59227684e-01,  2.46642798e-01, -1.87469915e-01,\n",
              "        -8.33279729e-01,  3.09609801e-01,  3.27019870e-01,\n",
              "         7.19247460e-01,  2.38111224e-02, -6.17075324e-01,\n",
              "        -9.02318716e-01, -2.04752058e-01, -4.03976813e-02,\n",
              "        -2.74646521e-01, -9.44256544e-01, -1.17134541e-01,\n",
              "        -2.56105065e-01,  5.61540842e-01, -6.98730648e-02,\n",
              "         1.27310053e-01, -7.11836338e-01,  1.60811797e-01,\n",
              "        -5.98538995e-01,  4.30050045e-01,  5.01246929e-01,\n",
              "        -9.24651623e-01, -5.31142116e-01,  2.97180433e-02,\n",
              "        -5.43936729e-01,  1.68865219e-01, -9.30133104e-01,\n",
              "         9.58091795e-01, -2.50125408e-01, -3.94633487e-02,\n",
              "         9.99999464e-01, -3.10781687e-01, -8.39686990e-01,\n",
              "         3.32637668e-01,  6.25643730e-02, -3.27604026e-01,\n",
              "         9.99997795e-01,  4.01018649e-01, -9.64499533e-01,\n",
              "        -3.52181047e-01,  2.09911928e-01, -2.66048580e-01,\n",
              "        -2.82459110e-01,  9.96943057e-01, -5.89676611e-02,\n",
              "         2.91301817e-01,  4.34913009e-01,  9.54686701e-01,\n",
              "        -9.78556514e-01,  5.87534428e-01, -8.86502087e-01,\n",
              "        -9.49226618e-01,  9.38674688e-01,  8.93809319e-01,\n",
              "        -1.01006985e-01, -5.49703181e-01, -5.23643428e-03,\n",
              "        -1.29091546e-01,  2.03669533e-01, -9.42305744e-01,\n",
              "         5.41646242e-01,  3.72669131e-01, -2.76559200e-02,\n",
              "         8.53446007e-01, -8.04505169e-01, -3.18391562e-01,\n",
              "         2.31349692e-01,  1.14214905e-01,  3.61928582e-01,\n",
              "         6.51258975e-02,  4.08142209e-01, -1.79886505e-01,\n",
              "        -4.16058227e-02, -1.98752314e-01, -1.80619657e-02,\n",
              "        -9.59356964e-01, -8.50294251e-03,  9.99997616e-01,\n",
              "         1.74718767e-01, -3.82000327e-01, -1.76070318e-01,\n",
              "        -2.24566814e-02, -3.72011185e-01,  2.52964914e-01,\n",
              "         3.61799955e-01, -1.73660889e-01, -8.12777996e-01,\n",
              "        -1.84779897e-01, -9.04358208e-01, -9.72242951e-01,\n",
              "         7.09920704e-01,  1.22588560e-01, -2.35891595e-01,\n",
              "         9.98499632e-01,  2.41318256e-01,  7.07069337e-02,\n",
              "        -2.10074425e-01,  1.90344453e-01,  4.26438712e-02,\n",
              "         5.49045801e-01, -2.43167371e-01,  9.54624355e-01,\n",
              "        -1.18585661e-01,  3.52865607e-01,  7.69407451e-01,\n",
              "         1.56783864e-01, -2.77091682e-01, -5.32793522e-01,\n",
              "        -5.41478582e-02, -8.84217858e-01,  6.59791306e-02,\n",
              "        -9.17464793e-01,  9.40718174e-01, -2.78057069e-01,\n",
              "         2.12802842e-01,  8.21586549e-02, -9.14389119e-02,\n",
              "         9.99999225e-01,  1.64650604e-01,  5.75189054e-01,\n",
              "        -4.45423007e-01,  8.25473547e-01, -8.96766901e-01,\n",
              "        -7.04367936e-01, -2.32114628e-01,  9.75804031e-02,\n",
              "         3.09415877e-01, -2.24417597e-01,  1.45032033e-01,\n",
              "        -9.44486499e-01, -9.57699716e-02, -1.35568842e-01,\n",
              "        -9.71502244e-01, -9.82321620e-01,  5.95214844e-01,\n",
              "         7.26971269e-01, -5.86413257e-02, -4.66319263e-01,\n",
              "        -5.43539226e-01, -4.98646617e-01,  8.65430981e-02,\n",
              "        -1.19138032e-01, -8.95065784e-01,  5.29094875e-01,\n",
              "        -1.47405654e-01,  3.68371069e-01, -1.29226983e-01,\n",
              "         3.84795219e-01, -1.90134227e-01,  7.64306724e-01,\n",
              "         3.94210488e-01,  8.61140415e-02, -1.33413821e-04,\n",
              "        -7.26386189e-01,  6.96396589e-01, -7.56366968e-01,\n",
              "         1.31954271e-02, -3.22473198e-02,  9.99999702e-01,\n",
              "        -2.46137500e-01,  6.00932986e-02,  6.61291599e-01,\n",
              "         5.66651344e-01, -2.98796762e-02,  9.94942263e-02,\n",
              "         1.87718347e-01,  1.13577999e-01,  2.56042629e-01,\n",
              "         4.16822076e-01, -6.94965005e-01, -2.98554778e-01,\n",
              "         4.85293984e-01, -3.96476805e-01, -1.18701227e-01,\n",
              "         7.48621762e-01,  1.98321417e-01, -7.28264377e-02,\n",
              "         6.72788993e-02, -3.42085883e-02,  9.96680140e-01,\n",
              "        -1.12268873e-01,  3.43316495e-02, -3.58027250e-01,\n",
              "         7.85405487e-02, -2.01504469e-01, -5.93540788e-01,\n",
              "         9.99991000e-01,  2.55759090e-01, -8.00834149e-02,\n",
              "        -9.80721593e-01,  8.57757106e-02, -8.84291470e-01,\n",
              "         9.98521566e-01,  7.33059049e-01, -7.70854533e-01,\n",
              "         3.34853351e-01,  2.26095155e-01, -3.61387916e-02,\n",
              "         6.63746953e-01, -1.39148980e-01, -2.07815528e-01,\n",
              "         4.91101928e-02,  7.67068639e-02,  9.35157776e-01,\n",
              "        -3.22311997e-01, -9.41077113e-01, -5.01454115e-01,\n",
              "         2.38329634e-01, -9.36645865e-01,  9.51109886e-01,\n",
              "        -3.95464540e-01, -1.11007929e-01, -2.20094949e-01,\n",
              "         4.37655210e-01,  6.86932921e-01, -1.32405609e-01,\n",
              "        -9.66536224e-01, -3.26283723e-02, -3.95021811e-02,\n",
              "         9.48272169e-01,  6.12536371e-02, -3.50337565e-01,\n",
              "        -8.84174168e-01, -4.08193141e-01,  4.56497930e-02,\n",
              "         2.68022418e-01, -9.14036214e-01,  9.49233711e-01,\n",
              "        -9.72822845e-01,  2.96122521e-01,  9.99980330e-01,\n",
              "         1.68159157e-01, -6.94246292e-01,  7.92567953e-02,\n",
              "        -2.73781747e-01,  1.18130401e-01,  2.00043514e-01,\n",
              "         4.91373926e-01, -9.36287224e-01, -1.87114939e-01,\n",
              "        -9.16603059e-02,  1.47290036e-01, -4.57071178e-02,\n",
              "         4.43146080e-01,  6.23742342e-01,  1.32681713e-01,\n",
              "        -3.26280981e-01, -4.53977257e-01, -1.65416487e-02,\n",
              "         3.11954051e-01,  6.86536908e-01, -2.19376132e-01,\n",
              "         1.27245989e-02,  2.64962204e-02, -5.30635752e-02,\n",
              "        -8.95224810e-01, -7.58704990e-02, -1.49914235e-01,\n",
              "        -9.86456990e-01,  5.29075861e-01, -9.99999464e-01,\n",
              "        -2.53180861e-01, -3.89638424e-01, -1.10863946e-01,\n",
              "         7.75813043e-01, -3.85470642e-03, -2.40925197e-02,\n",
              "        -6.87137127e-01,  3.22064966e-01,  8.16545010e-01,\n",
              "         7.00253844e-01, -1.39681071e-01,  2.78741509e-01,\n",
              "        -6.06806159e-01,  4.68212068e-02, -2.20994558e-02,\n",
              "         1.71406001e-01,  1.66437939e-01,  6.69284523e-01,\n",
              "        -7.68628493e-02,  9.99999762e-01,  4.80826236e-02,\n",
              "        -3.67757589e-01, -9.56071734e-01,  1.37532458e-01,\n",
              "        -1.45945668e-01,  9.99819696e-01, -8.34232926e-01,\n",
              "        -9.10560131e-01,  2.47095719e-01, -3.96522939e-01,\n",
              "        -7.76660800e-01,  1.20118529e-01, -6.96644709e-02,\n",
              "        -5.71667612e-01, -2.44300887e-01,  9.49570954e-01,\n",
              "         8.30785036e-01, -3.73762578e-01,  3.29327554e-01,\n",
              "        -2.66069502e-01, -2.86363423e-01,  1.94675417e-03,\n",
              "        -2.69065678e-01,  9.75802958e-01,  3.35265547e-01,\n",
              "         8.36856425e-01,  6.40837193e-01,  6.07292391e-02,\n",
              "         9.42406416e-01,  1.55342132e-01,  4.94064957e-01,\n",
              "         5.67393051e-03,  9.99990463e-01,  2.24621221e-01,\n",
              "        -9.10102189e-01,  3.92772287e-01, -9.75669861e-01,\n",
              "        -9.50779542e-02, -9.35609341e-01,  1.25924259e-01,\n",
              "         1.52509827e-02,  7.90361166e-01, -1.73911586e-01,\n",
              "         9.26586390e-01,  3.15689743e-01,  3.20285256e-03,\n",
              "         2.14188591e-01,  5.05895257e-01,  2.34152049e-01,\n",
              "        -8.87949288e-01, -9.71748531e-01, -9.73419905e-01,\n",
              "         1.56803757e-01, -3.71650279e-01,  4.21127416e-02,\n",
              "         1.46693602e-01,  5.84844947e-02,  2.40403041e-01,\n",
              "         2.97605485e-01, -9.99985695e-01,  9.00348127e-01,\n",
              "         3.05088311e-01, -7.29377419e-02,  9.38695788e-01,\n",
              "         3.17615300e-01,  1.25722989e-01,  1.52543083e-01,\n",
              "        -9.75894034e-01, -9.56641853e-01, -2.67000228e-01,\n",
              "        -1.69375479e-01,  7.40240633e-01,  4.87452090e-01,\n",
              "         8.31477463e-01,  2.66380966e-01, -3.94035131e-01,\n",
              "        -1.00475289e-01,  3.39597791e-01, -5.28897569e-02,\n",
              "        -9.86447573e-01,  3.05174410e-01,  3.40146989e-01,\n",
              "        -9.27654922e-01,  9.40366387e-01, -4.29568291e-01,\n",
              "        -9.25208703e-02,  5.44942558e-01,  6.05882592e-02,\n",
              "         9.09175634e-01,  7.22549081e-01,  3.41517597e-01,\n",
              "         6.30326644e-02,  4.11322981e-01,  8.43738317e-01,\n",
              "         9.36017573e-01,  9.75670755e-01,  9.66167822e-02,\n",
              "         7.55496025e-01,  3.17225069e-01,  3.94444853e-01,\n",
              "         3.59128654e-01, -9.09251213e-01,  1.33179296e-02,\n",
              "         1.57645065e-02, -8.09727982e-02,  1.03889413e-01,\n",
              "        -1.09999172e-01, -9.43637729e-01,  3.24728668e-01,\n",
              "        -5.81945106e-02,  3.79160017e-01, -3.96338999e-01,\n",
              "         1.99777544e-01, -3.22176576e-01, -7.11401626e-02,\n",
              "        -6.02083027e-01, -4.53321993e-01,  4.53373492e-01,\n",
              "         1.61087632e-01,  8.86166930e-01,  3.26387107e-01,\n",
              "         7.10205222e-03, -4.83917058e-01, -1.89277008e-02,\n",
              "         1.90920502e-01, -8.83068383e-01,  9.00498271e-01,\n",
              "         5.01685180e-02,  2.70829022e-01, -1.46087453e-01,\n",
              "        -1.12084121e-01,  6.44348323e-01, -2.18615994e-01,\n",
              "        -2.23633125e-01, -2.18056396e-01, -6.33494079e-01,\n",
              "         7.94599771e-01, -4.87838201e-02, -4.02745485e-01,\n",
              "        -3.94038618e-01,  5.47496438e-01,  2.00758845e-01,\n",
              "         9.77521777e-01,  9.67468843e-02,  9.67845246e-02,\n",
              "        -1.24762719e-02, -1.35928795e-01,  2.45286375e-01,\n",
              "        -1.80026248e-01, -9.99984860e-01,  2.40942389e-01,\n",
              "         2.86464781e-01,  1.47755006e-02,  1.55409232e-01,\n",
              "        -2.06393823e-01,  1.09946728e-01, -9.65636969e-01,\n",
              "        -1.05919115e-01, -1.06210597e-01, -2.31140509e-01,\n",
              "        -3.97956342e-01, -2.07411513e-01,  3.41254890e-01,\n",
              "         5.85511625e-01,  2.62706906e-01,  8.46819758e-01,\n",
              "         1.05364971e-01,  5.26910663e-01,  4.29066598e-01,\n",
              "         1.64702788e-01, -5.69369495e-01,  8.56210887e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWagU1D8qO9V",
        "colab_type": "text"
      },
      "source": [
        "#### extracting embedding from tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crvaTpf4OeaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get tokenizer and model \n",
        "max_seq_length = 128\n",
        "tokenizer = get_tokenizer()\n",
        "model = embedding_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU2lY2vXJ0l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to convert clean tweets into embeddings.\n",
        "\n",
        "def convert_tweets_into_embeddings(dataframe, tokenizer, model, max_seq_length =128):\n",
        "  # tokenize the tweets\n",
        "  dataframe['clean_tweet'] = dataframe['clean_tweet'].apply(lambda x: tokenizer.tokenize(x))\n",
        "  dataframe['clean_tweet'] = dataframe['clean_tweet'].apply(lambda x: [\"[CLS]\"] + x + [\"[SEP]\"])\n",
        "\n",
        "  # get input_ids, input_masks, input_segments\n",
        "  dataframe['input_ids'] = dataframe['clean_tweet'].apply(lambda x: get_ids(x, tokenizer, max_seq_length))\n",
        "  dataframe['input_masks'] = dataframe['clean_tweet'].apply(lambda x: get_masks(x, max_seq_length))\n",
        "  dataframe['input_segments'] = dataframe['clean_tweet'].apply(lambda x: get_segments(x, max_seq_length))\n",
        "\n",
        "  # convert them into numpy arrays\n",
        "  input_ids = np.array(dataframe['input_ids'].values.tolist())\n",
        "  input_masks = np.array(dataframe['input_masks'].values.tolist())\n",
        "  input_segments = np.array(dataframe['input_segments'].values.tolist())\n",
        "\n",
        "  pool_embs, all_embs = model.predict([input_ids, input_masks, input_segments])\n",
        "  return pool_embs, all_embs"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWTLe2xRIRe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get embeddings \n",
        "bert_train = convert_tweets_into_embeddings(train_data, tokenizer, model, max_seq_length =128)\n",
        "\n",
        "bert_test = convert_tweets_into_embeddings(test_data, tokenizer, model, max_seq_length =128)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw6RZSqdBlDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the preprocessed tweets\n",
        "train_file = open(save_path + \"bert_train.pickle\", mode='wb')\n",
        "pickle.dump(bert_train, train_file)\n",
        "train_file.close()\n",
        "\n",
        "test_file = open(save_path + \"bert_test.pickle\", mode='wb')\n",
        "pickle.dump(bert_test, test_file)\n",
        "test_file.close()"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBeaTZk-Ngmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}