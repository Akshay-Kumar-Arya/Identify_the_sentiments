{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnlm vectors from tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "up1OYuJfvVdi",
        "K4noMgFP3ADX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshay-Kumar-Arya/Identify_the_sentiments/blob/master/nnlm_vectors_from_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-g_CPLtHrFq",
        "colab_type": "text"
      },
      "source": [
        "# Identify the Sentiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG9n3fVzsGrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install modules\n",
        "!pip install -q tensorflow\n",
        "!pip install -q tensorflow_hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScDKcwmuRJ8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "33bf8798-b4d9-4d25-ab07-b701ed88cd39"
      },
      "source": [
        "# import Modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import re\n",
        "import spacy\n",
        "import pickle\n",
        "#import math\n",
        "\n",
        "# To visualize tweets upto larger width\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "print(\"TF version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version:  2.2.0\n",
            "Hub version:  0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m17YKicdRCoa",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRfhnlCsQcbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2f45d941-7341-49bf-cc79-a884d3e01970"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHVNZms4HwAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data path\n",
        "training_data_path = \"/content/gdrive/My Drive/Identify_the_sentiments/train.csv\"\n",
        "test_data_path =  \"/content/gdrive/My Drive/Identify_the_sentiments/test.csv\"\n",
        "\n",
        "save_path = \"/content/gdrive/My Drive/Identify_the_sentiments/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj4_Wb4nQ0B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading data from csv\n",
        "train_data = pd.read_csv(training_data_path)\n",
        "test_data = pd.read_csv(test_data_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlPJGbKvQ-jW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "3d9c625e-7e66-42b8-e6fc-e64363e4e2de"
      },
      "source": [
        "# data visualization\n",
        "print(f\"Number of training examples: {train_data.shape[0]}\", '\\n')\n",
        "print(f\"Number of test examples: {test_data.shape[0]}\", '\\n')\n",
        "\n",
        "print(f\"The fraction of positive and negative comments:\")\n",
        "print(train_data['label'].value_counts(normalize = True), '\\n')\n",
        "\n",
        "print(\"Training Dataframe:\")\n",
        "print(train_data.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 7920 \n",
            "\n",
            "Number of test examples: 1953 \n",
            "\n",
            "The fraction of positive and negative comments:\n",
            "0    0.744192\n",
            "1    0.255808\n",
            "Name: label, dtype: float64 \n",
            "\n",
            "Training Dataframe:\n",
            "   id  ...                                                                                                                                tweet\n",
            "0   1  ...     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone\n",
            "1   2  ...  Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/\n",
            "2   3  ...          We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu\n",
            "3   4  ...                     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/\n",
            "4   5  ...         What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXYPslMkRZt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing URLs from data\n",
        "train_data['clean_tweet'] = train_data['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "test_data['clean_tweet'] = test_data['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVg_KYKz5BFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove twitter handles\n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt4Rc4j_Sa_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove punctuations\n",
        "punctuation = '.,\\'!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
        "              \n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].apply(lambda x: \"\".join(ch for ch in x if ch not in set(punctuation)))\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].apply(lambda x: \"\".join(ch for ch in x if ch not in set(punctuation)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4UL7TouVqQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to lower case\n",
        "\n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].str.lower()\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].str.lower()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0hK9C9WYA8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove the numbers\n",
        "\n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].str.replace(\"[0-9]\", \" \")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6RVYH9MGHJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove white spaces\n",
        "\n",
        "train_data['clean_tweet'] = train_data['clean_tweet'].apply(lambda x: ' '.join(x.split()))\n",
        "test_data['clean_tweet'] = test_data['clean_tweet'].apply(lambda x: ' '.join(x.split()))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC4gL8A_QZg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lammetizing the tweets\n",
        "# converting them into their base form\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# function to lemmatize text\n",
        "def lemmatization(texts):\n",
        "    output = []\n",
        "    for i in texts:\n",
        "        s = [token.lemma_ for token in nlp(i)]\n",
        "        output.append(' '.join(s))\n",
        "    return output\n",
        "\n",
        "train_data['clean_tweet'] = lemmatization(train_data['clean_tweet'])\n",
        "test_data['clean_tweet'] = lemmatization(test_data['clean_tweet'])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g0ekoiYU37Y",
        "colab_type": "text"
      },
      "source": [
        "#### Load the embedding layer\n",
        "The URL for the module is https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1.\n",
        "\n",
        "This embedding takes a batch of text tokens in a 1-D tensor of strings as input. It then embeds the separate tokens into a 128-dimensional space.\n",
        "\n",
        "NB: this model can be used as a sentence embedding module. The module will process each token by removing punctuation and splitting on spaces. It then averages the word embeddings over a sentence to give a single embedding vector. However, we can also use it as a word embedding module, and can pass each word in the input sentence as a separate token.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoRYtWiTSnoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nnlm-en-dim128 embedding model\n",
        "embed = hub.load(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6VOtLj1YDrY",
        "colab_type": "text"
      },
      "source": [
        "#### pool embedding (one vector for one sentence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYcBoSTKWTn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nnlm_vectors(x):\n",
        "  return embed(x).numpy()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS97mdobUGCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build batches list\n",
        "list_train = [train_data[i:i+100] for i in range(0,train_data.shape[0],100)]\n",
        "list_test = [test_data[i:i+100] for i in range(0,test_data.shape[0],100)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywKtCVe_UGEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract embeddings\n",
        "nnlm_train = [nnlm_vectors(x['clean_tweet']) for x in list_train]\n",
        "nnlm_test = [nnlm_vectors(x['clean_tweet']) for x in list_test]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYFahmPeUGHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenating \n",
        "nnlm_train_new = np.concatenate(nnlm_train, axis = 0)\n",
        "nnlm_test_new = np.concatenate(nnlm_test, axis = 0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw6RZSqdBlDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the preprocessed tweets\n",
        "train_file = open(save_path + \"nnlm_train.pickle\", mode='wb')\n",
        "pickle.dump(nnlm_train_new, train_file)\n",
        "train_file.close()\n",
        "\n",
        "test_file = open(save_path + \"nnlm_test.pickle\", mode='wb')\n",
        "pickle.dump(nnlm_test_new, test_file)\n",
        "test_file.close()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBeaTZk-Ngmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
